{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Explore and Collect the Dataset (Week 1)\n",
    "\n",
    "Download and understand the job market dataset and prepare it for further processing.\n",
    "\n",
    "Tasks:\n",
    "Download Dataset:\n",
    "\n",
    "Download the dataset from Kaggle.\n",
    "Explore the CSV file to understand its structure: job title, company, location, job description, post date, etc.\n",
    "Understand the Data:\n",
    "\n",
    "Examine key features such as:\n",
    "Job Title: What roles are being posted?\n",
    "Company: Which companies are posting the most jobs?\n",
    "Location: Where are most jobs located?\n",
    "Job Function: What are the most common job functions (e.g., IT, HR, Marketing)?\n",
    "Employment Type: Full-time, part-time, contract, etc.\n",
    "Skills Learned:\n",
    "Exploratory Data Analysis (EDA): Learn how to understand datasets before performing operations.\n",
    "Technologies:\n",
    "Pandas (for data exploration in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸš€Principal Geotechnical Engineer (ESOP)(Bonus)(Fully Remote)ðŸš€'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "chunk_size = 10000\n",
    "\n",
    "chunks = [ ]\n",
    "\n",
    "for index, chunk in enumerate(pd.read_csv('data/postings.csv', chunksize=chunk_size)): \n",
    "    # print(f\"reading chunk {index}\")\n",
    "    # print(f\"shape is  {chunk.shape}\")\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "    \n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "    \n",
    "# df.head()\n",
    "# df.info()\n",
    "# df.describe()\n",
    "# df[['views','job_id']].head(10)\n",
    "\n",
    "# df.head(5)\n",
    "\n",
    "# print(df.iloc[0])\n",
    "# print(df.loc[0])\n",
    "\n",
    "\n",
    "# df[(df['min_salary'] > 35) & (df['pay_period'] == 'HOURLY')]\n",
    "\n",
    "# df.groupby('pay_period').sum()\n",
    "\n",
    "df.head(1)\n",
    "\n",
    "df['title'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables refreshed.\n",
      "postgresql://postgres:root@localhost:5432/data_engineering_job_postings\n",
      "Connected to database: data_engineering_job_postings\n",
      "Database connection successful!\n",
      "Table created successfully or already exists.\n",
      "Data retrieved successfully from table 'postings':\n",
      "Empty DataFrame\n",
      "Columns: [id, name, age, created_at]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,  Column, Integer, String, DateTime\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy.orm import  declarative_base\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Define the base class for SQLAlchemy models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define your table as a model\n",
    "class Posting(Base):\n",
    "    __tablename__ = 'postings'  # Table name in the database\n",
    "    id = Column(Integer, primary_key=True)  # Primary key\n",
    "    name = Column(String, nullable=False)     # User name\n",
    "    age = Column(Integer)                      # User age\n",
    "    created_at = Column(DateTime)             # Record creation timestamp\n",
    "\n",
    "def create_table(engine):\n",
    "    # Create all tables defined in the Base metadata\n",
    "    Base.metadata.create_all(engine)\n",
    "    print(\"Table created successfully or already exists.\")\n",
    "\n",
    "def refresh_env_variables():\n",
    "    \"\"\"Refreshes the environment variables by reloading them from the .env file.\"\"\"\n",
    "    load_dotenv()  # Load the environment variables from the .env file\n",
    "\n",
    "    # Optionally, you can clear specific variables if you want to ensure they are refreshed\n",
    "    os.environ.pop('DB_USERNAME', None)\n",
    "    os.environ.pop('DB_PASSWORD', None)\n",
    "    os.environ.pop('DB_NAME', None)\n",
    "    os.environ.pop('DB_HOST', None)\n",
    "    os.environ.pop('DB_PORT', None)\n",
    "\n",
    "    # Reload the environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    print(\"Environment variables refreshed.\")\n",
    "    \n",
    "def setup_database_connection():\n",
    "\n",
    "    # Retrieve PostgreSQL connection parameters from environment variables\n",
    "    username = os.getenv('DB_USERNAME')\n",
    "    password = os.getenv('DB_PASSWORD')\n",
    "    database = os.getenv('DB_NAME')\n",
    "    host = os.getenv('DB_HOST', 'localhost')  # Default to 'localhost' if not set\n",
    "    port = os.getenv('DB_PORT', '5432')        # Default to '5432' if not set\n",
    "\n",
    "    # Check if required environment variables are set\n",
    "    if not username or not password or not database:\n",
    "        raise ValueError(\"Database connection parameters are not set in the environment variables.\")\n",
    "\n",
    "    # Create a connection string\n",
    "    connection_string = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "    print(connection_string)\n",
    "    # Create a SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Check the database connection\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            print(\"Database connection successful!\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Database connection failed: {e}\")\n",
    "        return None  # Return None if the connection fails\n",
    "\n",
    "    return engine  # Return the engine if the connection is successful\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transfer_data_to_postgres(engine):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    csv_file_path = 'path/to/your/file.csv'  # Update this path\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Transfer the data to PostgreSQL\n",
    "    try:\n",
    "        df.to_sql('your_table_name', engine, if_exists='append', index=False)\n",
    "        print(\"Data transferred successfully!\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Data transfer failed: {e}\")\n",
    "\n",
    "def read_data_from_table(engine, table_name):\n",
    "    \"\"\"Read all data from the specified table.\"\"\"\n",
    "    try:\n",
    "        # Read data from the specified table into a pandas DataFrame\n",
    "        df = pd.read_sql_table(table_name, con=engine)\n",
    "        print(f\"Data retrieved successfully from table '{table_name}':\")\n",
    "        print(df)\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Failed to read data from table '{table_name}': {e}\")\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    engine = setup_database_connection()\n",
    "    if engine:\n",
    "        create_table(engine)\n",
    "        read_data_from_table(engine, 'postings')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    refresh_env_variables()\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
